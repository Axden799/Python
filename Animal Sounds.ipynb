{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\axel\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: joblib>=0.12 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (0.13.2)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (1.14.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (0.44.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (0.21.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (1.18.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: llvmlite>=0.29.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.29.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\axel\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter_helpers in c:\\users\\axel\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jupyter_helpers) (0.24.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jupyter_helpers) (7.5.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jupyter_helpers) (2.4.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jupyter_helpers) (7.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\axel\\anaconda3\\lib\\site-packages (from pandas->jupyter_helpers) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from pandas->jupyter_helpers) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from pandas->jupyter_helpers) (1.18.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter_helpers) (5.1.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter_helpers) (4.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter_helpers) (3.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter_helpers) (4.3.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (0.1.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (4.4.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (45.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (0.13.3)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (0.4.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from IPython->jupyter_helpers) (2.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas->jupyter_helpers) (1.14.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->jupyter_helpers) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\axel\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->jupyter_helpers) (5.3.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter_helpers) (4.5.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter_helpers) (3.0.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter_helpers) (0.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (6.0.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jedi>=0.10->IPython->jupyter_helpers) (0.5.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\axel\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->jupyter_helpers) (0.1.7)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->jupyter_helpers) (18.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter_helpers) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter_helpers) (0.14.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (2.10.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\axel\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.7.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\axel\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (5.5.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\axel\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.6.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.4.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (1.4.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.3)\n",
      "Requirement already satisfied: mistune>=0.8.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.8.4)\n",
      "Requirement already satisfied: webencodings in c:\\users\\axel\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->jupyter_helpers) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install jupyter_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldatasetpath = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files'\n",
    "\n",
    "metadata = pd.read_csv('F:\\Essential Files\\Coding Projects\\senior design 2\\metadata.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "for row in range(0, 276):\n",
    "    name = \"\\\\\"\n",
    "    name = name + str(metadata.iloc[row,0])\n",
    "    file_name = os.path.join(fulldatasetpath + name)\n",
    "    \n",
    "    data = extract_features(file_name)\n",
    "    animal = metadata.iloc[row,1]\n",
    "    features.append([data, animal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf = pd.DataFrame(features, columns=['feature','animal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\axel\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\axel\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-utils in c:\\users\\axel\\anaconda3\\lib\\site-packages (1.0.13)\n",
      "Requirement already satisfied: Keras>=2.1.5 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from keras-utils) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (5.1.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (1.18.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\axel\\anaconda3\\lib\\site-packages (from Keras>=2.1.5->keras-utils) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install keras-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/6d/99aba8db04bf58193ed157dfe7e848494b93dd8aa3f6a4d1edfef318779c/grpcio-1.27.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/30/1b7ccde09bf0c535d11f18a574ed7d7572c729a8f754fd568b297be08b61/protobuf-3.11.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting numpy<2.0,>=1.16.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a9/38/f6d6d8635d496d6b4ed5d8ca4b9f193d0edc59999c3a63779cbc38aa650f/numpy-1.18.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting h5py (from keras-applications>=1.0.8->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/6b/7f62017e3f0b32438dd90bdc1ff0b7b1448b6cb04a1ed84f37b6de95cd7b/h5py-2.10.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/72/1c1498c1e908e0562b1e1cd30012580baa7d33b5b0ffdbeb5fde2462cc71/setuptools-45.2.0-py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: wrapt, six, numpy, keras-preprocessing, opt-einsum, tensorflow-estimator, gast, google-pasta, astor, h5py, keras-applications, grpcio, setuptools, markdown, wheel, absl-py, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, chardet, idna, certifi, urllib3, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, werkzeug, tensorboard, scipy, termcolor, tensorflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: spyder 3.3.6 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: astroid 2.2.5 requires typed-ast>=1.3.0; implementation_name == \"cpython\", which is not installed.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Axel\\\\Anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\.libs\\\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --ignore-installed --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.animal.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 77,059\n",
      "Trainable params: 77,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 62.5000%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 220 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 467us/step - loss: 19.2940 - accuracy: 0.4909 - val_loss: 4.4188 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.41877, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 199us/step - loss: 17.9792 - accuracy: 0.4273 - val_loss: 4.3092 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.41877 to 4.30920, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 15.9687 - accuracy: 0.4500 - val_loss: 7.8025 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.30920\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 82us/step - loss: 11.2619 - accuracy: 0.5909 - val_loss: 4.0040 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.30920 to 4.00404, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 11.1145 - accuracy: 0.5682 - val_loss: 3.0547 - val_accuracy: 0.6964\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.00404 to 3.05474, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 73us/step - loss: 8.8889 - accuracy: 0.6136 - val_loss: 2.1533 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.05474 to 2.15334, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 113us/step - loss: 7.7953 - accuracy: 0.6000 - val_loss: 1.6662 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.15334 to 1.66625, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 73us/step - loss: 5.8033 - accuracy: 0.6273 - val_loss: 1.6600 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.66625 to 1.65997, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 6.1059 - accuracy: 0.6545 - val_loss: 1.3265 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.65997 to 1.32646, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 122us/step - loss: 4.3827 - accuracy: 0.6500 - val_loss: 1.1102 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.32646 to 1.11025, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 113us/step - loss: 4.1891 - accuracy: 0.7136 - val_loss: 1.0679 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.11025 to 1.06788, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 150us/step - loss: 4.3950 - accuracy: 0.7136 - val_loss: 1.0121 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.06788 to 1.01209, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 122us/step - loss: 4.3980 - accuracy: 0.7091 - val_loss: 0.8646 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.01209 to 0.86457, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 3.4943 - accuracy: 0.7136 - val_loss: 0.7929 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.86457 to 0.79293, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 3.1761 - accuracy: 0.7136 - val_loss: 0.7605 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.79293 to 0.76055, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 3.4962 - accuracy: 0.6773 - val_loss: 0.7034 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.76055 to 0.70339, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 95us/step - loss: 2.4698 - accuracy: 0.7682 - val_loss: 0.7381 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.70339\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 104us/step - loss: 3.2132 - accuracy: 0.7318 - val_loss: 0.7139 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.70339\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 2.2641 - accuracy: 0.7409 - val_loss: 0.6232 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70339 to 0.62321, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 68us/step - loss: 2.7990 - accuracy: 0.7500 - val_loss: 0.4912 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.62321 to 0.49118, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 68us/step - loss: 2.0593 - accuracy: 0.7500 - val_loss: 0.5313 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.49118\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 1.9628 - accuracy: 0.7318 - val_loss: 0.5875 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.49118\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 68us/step - loss: 2.2034 - accuracy: 0.7273 - val_loss: 0.4967 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.49118\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 1.4003 - accuracy: 0.7955 - val_loss: 0.4971 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49118\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 68us/step - loss: 2.1965 - accuracy: 0.7136 - val_loss: 0.4623 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.49118 to 0.46231, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 68us/step - loss: 1.2682 - accuracy: 0.7864 - val_loss: 0.4939 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.46231\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 73us/step - loss: 1.5906 - accuracy: 0.8000 - val_loss: 0.4600 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.46231 to 0.45996, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 73us/step - loss: 1.4315 - accuracy: 0.7727 - val_loss: 0.4401 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.45996 to 0.44012, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 1.3789 - accuracy: 0.7636 - val_loss: 0.4344 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.44012 to 0.43439, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 122us/step - loss: 1.1133 - accuracy: 0.8136 - val_loss: 0.4809 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.43439\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 118us/step - loss: 1.1255 - accuracy: 0.8000 - val_loss: 0.4832 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.43439\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 82us/step - loss: 1.1216 - accuracy: 0.7864 - val_loss: 0.4697 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.43439\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 1.0770 - accuracy: 0.7955 - val_loss: 0.4388 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.43439\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8400 - accuracy: 0.8045 - val_loss: 0.4674 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.43439\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 1.0452 - accuracy: 0.7773 - val_loss: 0.5146 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.43439\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 1.2531 - accuracy: 0.7818 - val_loss: 0.5138 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.43439\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 1.0480 - accuracy: 0.7773 - val_loss: 0.5137 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.43439\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8123 - accuracy: 0.8273 - val_loss: 0.5223 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.43439\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.9026 - accuracy: 0.8045 - val_loss: 0.5150 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.43439\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 1.0401 - accuracy: 0.7909 - val_loss: 0.4968 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.43439\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8709 - accuracy: 0.8045 - val_loss: 0.4954 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.43439\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8607 - accuracy: 0.7909 - val_loss: 0.5294 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.43439\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.8003 - accuracy: 0.8136 - val_loss: 0.5190 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.43439\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.6215 - accuracy: 0.8455 - val_loss: 0.5093 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.43439\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6250 - accuracy: 0.8455 - val_loss: 0.5332 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.43439\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.7706 - accuracy: 0.8000 - val_loss: 0.5038 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.43439\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.6211 - accuracy: 0.8136 - val_loss: 0.4767 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.43439\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.7664 - accuracy: 0.8318 - val_loss: 0.4771 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.43439\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8624 - accuracy: 0.7955 - val_loss: 0.4563 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.43439\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6535 - accuracy: 0.8182 - val_loss: 0.4391 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.43439\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.7527 - accuracy: 0.7955 - val_loss: 0.4686 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.43439\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6261 - accuracy: 0.8045 - val_loss: 0.4864 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.43439\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6231 - accuracy: 0.8045 - val_loss: 0.4882 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.43439\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6399 - accuracy: 0.7909 - val_loss: 0.4604 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.43439\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.8272 - accuracy: 0.8091 - val_loss: 0.4512 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.43439\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.5074 - accuracy: 0.8273 - val_loss: 0.4465 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.43439\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.6146 - accuracy: 0.8364 - val_loss: 0.4420 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.43439\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.6552 - accuracy: 0.8136 - val_loss: 0.4584 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.43439\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.5352 - accuracy: 0.8182 - val_loss: 0.4595 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.43439\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.4953 - accuracy: 0.8636 - val_loss: 0.4523 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.43439\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.5441 - accuracy: 0.8409 - val_loss: 0.4222 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.43439 to 0.42216, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 60us/step - loss: 0.5612 - accuracy: 0.8455 - val_loss: 0.4288 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.42216\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.4048 - accuracy: 0.8591 - val_loss: 0.4320 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.42216\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.5482 - accuracy: 0.8318 - val_loss: 0.4492 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.42216\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.4196 - accuracy: 0.8636 - val_loss: 0.4626 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.42216\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.6154 - accuracy: 0.8182 - val_loss: 0.4754 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.42216\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.5046 - accuracy: 0.8227 - val_loss: 0.4839 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.42216\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.5218 - accuracy: 0.8364 - val_loss: 0.4852 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.42216\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.5012 - accuracy: 0.8409 - val_loss: 0.4967 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.42216\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.4868 - accuracy: 0.8227 - val_loss: 0.4781 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.42216\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.3738 - accuracy: 0.8864 - val_loss: 0.4623 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.42216\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.4390 - accuracy: 0.8500 - val_loss: 0.4469 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.42216\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.4826 - accuracy: 0.8409 - val_loss: 0.4623 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.42216\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 0.4098 - accuracy: 0.8636 - val_loss: 0.4746 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.42216\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 73us/step - loss: 0.4823 - accuracy: 0.8682 - val_loss: 0.4660 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.42216\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3973 - accuracy: 0.8364 - val_loss: 0.4514 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.42216\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.5284 - accuracy: 0.8273 - val_loss: 0.4242 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.42216\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3717 - accuracy: 0.8773 - val_loss: 0.4172 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.42216 to 0.41719, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 131us/step - loss: 0.3662 - accuracy: 0.8591 - val_loss: 0.4063 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.41719 to 0.40634, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 0.3576 - accuracy: 0.8409 - val_loss: 0.3939 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.40634 to 0.39394, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3560 - accuracy: 0.8636 - val_loss: 0.3949 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.39394\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3080 - accuracy: 0.8864 - val_loss: 0.3934 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.39394 to 0.39338, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.3180 - accuracy: 0.8864 - val_loss: 0.3816 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.39338 to 0.38158, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 118us/step - loss: 0.4175 - accuracy: 0.8636 - val_loss: 0.3694 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.38158 to 0.36944, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 77us/step - loss: 0.3388 - accuracy: 0.8773 - val_loss: 0.3796 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.36944\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 63us/step - loss: 0.3123 - accuracy: 0.8636 - val_loss: 0.3732 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.36944\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 54us/step - loss: 0.4129 - accuracy: 0.8500 - val_loss: 0.3675 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.36944 to 0.36752, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3301 - accuracy: 0.8864 - val_loss: 0.3688 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.36752\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.4441 - accuracy: 0.8727 - val_loss: 0.3704 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.36752\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3036 - accuracy: 0.8727 - val_loss: 0.3824 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.36752\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3912 - accuracy: 0.8682 - val_loss: 0.3819 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.36752\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3910 - accuracy: 0.8591 - val_loss: 0.3814 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.36752\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3590 - accuracy: 0.8545 - val_loss: 0.3704 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.36752\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3672 - accuracy: 0.8773 - val_loss: 0.3715 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.36752\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3460 - accuracy: 0.8864 - val_loss: 0.3733 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.36752\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.3616 - accuracy: 0.8545 - val_loss: 0.3718 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.36752\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 59us/step - loss: 0.2223 - accuracy: 0.9045 - val_loss: 0.3590 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.36752 to 0.35900, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 91us/step - loss: 0.2703 - accuracy: 0.8864 - val_loss: 0.3569 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.35900 to 0.35693, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 91us/step - loss: 0.3478 - accuracy: 0.8773 - val_loss: 0.3529 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.35693 to 0.35293, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 95us/step - loss: 0.2804 - accuracy: 0.9091 - val_loss: 0.3430 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.35293 to 0.34301, saving model to F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5\n",
      "Training completed in time:  0:00:04.303491\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='F:\\Essential Files\\Coding Projects\\senior design 2\\weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.949999988079071\n",
      "Testing Accuracy:  0.9107142686843872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        #print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat \n",
      "\n",
      "cat \t\t :  0.79212391376495361328125000000000\n",
      "chicken \t\t :  0.03475961089134216308593750000000\n",
      "dog \t\t :  0.17311644554138183593750000000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\kitty_1.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: chicken \n",
      "\n",
      "cat \t\t :  0.23848669230937957763671875000000\n",
      "chicken \t\t :  0.56453317403793334960937500000000\n",
      "dog \t\t :  0.19698019325733184814453125000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\doggo_1.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat \n",
      "\n",
      "cat \t\t :  0.68192803859710693359375000000000\n",
      "chicken \t\t :  0.07389143854379653930664062500000\n",
      "dog \t\t :  0.24418056011199951171875000000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\kitty_2.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: chicken \n",
      "\n",
      "cat \t\t :  0.31097909808158874511718750000000\n",
      "chicken \t\t :  0.35476472973823547363281250000000\n",
      "dog \t\t :  0.33425620198249816894531250000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\doggo_2.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat \n",
      "\n",
      "cat \t\t :  0.61128163337707519531250000000000\n",
      "dog \t\t :  0.38871833682060241699218750000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\kitty_3.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog \n",
      "\n",
      "cat \t\t :  0.30033823847770690917968750000000\n",
      "dog \t\t :  0.69966185092926025390625000000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\doggo_3.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog \n",
      "\n",
      "cat \t\t :  0.01554717961698770523071289062500\n",
      "dog \t\t :  0.98445278406143188476562500000000\n"
     ]
    }
   ],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\dog_barking_20.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'F:\\Essential Files\\Coding Projects\\senior design 2\\wav_files\\dog_barking_100.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
